id,title,year,country,sector,harm_type,risk_severity,stakeholders,summary,source,organization,what_went_wrong,prevention,topic
101,YouTube Kids surfaced disturbing content,2015,USA,News/Media,Misinformation,High,Children; Parents,Inappropriate and misleading videos appeared in YouTube Kids recommendations.,https://incidentdatabase.ai,YouTube,Weak content filters allowed disturbing material in kids app.,Strengthen review systems; human moderation for kids content.,misinformation
102,Facebook news feed amplified false election stories,2016,USA,Social Media,Misinformation,Critical,Voters; General public,False political stories spread widely through engagement-optimized ranking during the election season.,https://incidentdatabase.ai,Facebook,Engagement optimization favored sensational falsehoods; limited fact-check integration.,Downrank debunked claims; integrate fact-check signals; friction for reshares.,misinformation
103,Cambridge Analytica microtargeting controversy,2016,USA,Advertising,Privacy,High,Voters; Platform users,Opaque data harvesting and profiling enabled manipulative political ads.,https://incidentdatabase.ai,Facebook; Cambridge Analytica,Insufficient consent and transparency for sensitive microtargeting.,Limit sensitive targeting; ad transparency; independent audits.,bias
104,Twitter ranking showed partisan skew concerns,2020,USA,Social Media,Bias,Medium,Voters; Journalists,Analyses suggested timeline ranking sometimes amplified particular partisan outlets and frames.,https://incidentdatabase.ai,Twitter,Optimized for engagement without balancing viewpoint diversity or credibility.,Use credibility signals; diversify sources; expose ranking controls.,bias
105,COVID-19 health misinformation on YouTube,2020,Global,News/Media,Misinformation,Critical,General public; Health agencies,Misleading health claims were recommended alongside legitimate content early in the pandemic.,https://incidentdatabase.ai,YouTube,Watch-time objective over reliability; weak early enforcement of medical policies.,Elevate authoritative sources; stricter enforcement; reduce borderline promotion.,misinformation
106,Google Image search gender role bias,2015,Global,Search,Bias,High,Women; Job seekers,"Search results underrepresented women in leadership roles, reinforcing stereotypes.",https://incidentdatabase.ai,Google,Training data reflected historical bias and lacked counterbalancing signals.,Audit representational bias; fairness constraints; diversify training data.,bias
107,TikTok election misinformation spread,2022,Global,Social Media,Misinformation,High,Voters; Young users,Election-related falsehoods circulated rapidly on TikTok with delayed moderation responses.,https://incidentdatabase.ai,TikTok,Short-form virality made detection hard; limited context windows.,Proactive detection for election terms; friction for reshares; fact-check integrations.,misinformation
108,Deepfake of leader used for wartime disinformation,2022,Ukraine,News/Media,Misinformation,Critical,Civilians; Military,A fabricated surrender video attempted to erode public morale and trust.,https://incidentdatabase.ai,Unknown actors,Deepfake generation and rapid spread exploited low verification during crisis.,Watermark and provenance for official communications; takedown SLAs; user education.,misinformation
109,CNET used AI to write finance articles with errors,2023,USA,Newsroom,Misinformation,Medium,Readers,AI-written explainers contained factual and calculation mistakes before stronger review.,https://incidentdatabase.ai,CNET,Insufficient editorial oversight and disclosure for AI-generated content.,Mandatory human fact-check; disclosure; restrict AI use to low-risk drafts.,misinformation
110,Sports Illustrated articles under non-existent authors,2023,USA,Newsroom,Misinformation,Medium,Readers,"Stories appeared under fake author profiles with AI-like images, eroding trust.",https://incidentdatabase.ai,Sports Illustrated (publisher),Opaque authorship and reliance on vendor-provided AI content without clear policy.,Label AI contributions; real author accountability; vendor audits.,misinformation
111,Political deepfake robocall told voters to abstain,2024,USA,Elections,Misinformation,Critical,Voters,An audio deepfake mimicking a political figure told voters not to participate in a primary.,https://incidentdatabase.ai,Unknown actors,Voice cloning plus mass-calling exploited regulatory gaps.,Authenticate campaign communications; traceable caller ID; rapid reporting channels.,misinformation
112,Google News clustering mixed unrelated stories,2018,Global,News/Media,Misinformation,Low,Readers,"Automated clustering occasionally grouped unrelated stories, confusing readers about context.",https://incidentdatabase.ai,Google,Weak disambiguation for similar headlines and entities.,Improve entity resolution; add human QA for trending clusters; clearer provenance.,misinformation
113,Headline A/B testing skewed framing toward sensationalism,2019,USA,Newsroom,Bias,Medium,Readers; Editors,"Automated headline selection optimized clicks, leading to sensational framing on sensitive topics.",https://incidentdatabase.ai,Multiple publishers,Objective focused on CTR without guardrails for sensitive coverage.,Multi-objective optimization including harm metrics; editorial review for sensitive beats.,bias
114,Overbroad moderation sweep removed legitimate news,2021,Australia,Social Media,Misinformation,High,Readers; Publishers,"A policy enforcement sweep removed legitimate news pages, limiting access to reliable sources.",https://incidentdatabase.ai,Facebook,Overly broad rollout without robust exceptions or appeals.,Stage rollouts; whitelist verified outlets; rapid restoration process.,bias
115,Search autocomplete suggested conspiracy completions,2017,Global,Search,Misinformation,Medium,General public,Autocomplete suggested misleading conspiracy queries that nudged users toward false content.,https://incidentdatabase.ai,Multiple search engines,"Predictions optimized for frequency and engagement, not credibility.",Apply credibility filters; block harmful completions; context panels.,misinformation
116,AI-generated local news sites pushed sponsored narratives,2024,USA,Newsroom,Misinformation,High,Readers; Local communities,Low-cost AI content farms published large volumes of lightly-edited sponsored or partisan stories as local news.,https://incidentdatabase.ai,Various operators,Opaque funding and mass AI content production without editorial standards.,Require disclosure; platform labeling; ad network policies against covert propaganda.,misinformation
